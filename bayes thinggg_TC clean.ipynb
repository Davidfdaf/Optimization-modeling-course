{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62577c2e-79ba-4f41-8df2-2ba7a6c2b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(tickers, start, end, give = \"R\", adj_close = True, dividend = True):#read in stock data  \n",
    "    \"\"\"\n",
    "    tickers: tickers to read \n",
    "    start, end: dates in datetime.datetime(2015,12,1) format\n",
    "    give: return prices or returns \n",
    "    adj_close: use adjusted or unadjusted price\n",
    "    dividend: include dividend?\n",
    "    \"\"\"\n",
    "    \n",
    "    if give=='D':\n",
    "        adj_close=False\n",
    "        dividend = True\n",
    "    \n",
    "    stocks = pd.DataFrame()\n",
    "    if (adj_close == True):\n",
    "        dividend = False\n",
    "        stocks[tickers] = data.DataReader(tickers, 'yahoo', start, end)['Adj Close']\n",
    "    else:\n",
    "        stocks[tickers] = data.DataReader(tickers, 'yahoo', start, end)['Close']\n",
    "            \n",
    "        if (dividend == True): \n",
    "            stock_div = pd.DataFrame(index=stocks.index)\n",
    "            for tick in tickers:\n",
    "                stock_div[tick+' div'] = data.DataReader(tick, 'yahoo-dividends', start, end)[\"value\"]\n",
    "      \n",
    "    just_stocks=stocks\n",
    "    if (dividend == True):\n",
    "        stocks = pd.concat([stocks,stock_div],axis=1)\n",
    "        stocks = stocks.fillna(0)\n",
    "        \n",
    "    if(give == \"R\"):\n",
    "        #Adding dividends to price appreciation on a daily percent return basis -useful for all analysis\n",
    "        raw_returns=pd.DataFrame()\n",
    "        for tick in tickers:\n",
    "            if (dividend == True):\n",
    "                raw_returns[tick] = stocks[tick].pct_change() + stocks[tick+' div']/stocks[tick] \n",
    "                #dividends are actually added on the day before they should be added but this error is neglegible\n",
    "            else:\n",
    "                raw_returns[tick] = stocks[tick].pct_change()\n",
    "        returns=raw_returns[1:]\n",
    "        return returns[np.isfinite(returns).all(1)]\n",
    "        \n",
    "    if(give == \"P\"):\n",
    "        return just_stocks\n",
    "    \n",
    "    if(give==\"D\"):\n",
    "        dividend = pd.DataFrame(np.array(stocks.iloc[:,len(just_stocks.columns):])/np.array(stocks.iloc[:,:len(just_stocks.columns)])).set_index(just_stocks.index)\n",
    "        dividend.columns=just_stocks.columns\n",
    "        return dividend\n",
    "\n",
    "def calculate_posterior_mean(like_pop, prior_pop):\n",
    "    mu0 = prior_pop.mean()\n",
    "    w0 = prior_pop.std()\n",
    "    dbar = like_pop.mean()\n",
    "    w = like_pop.std()\n",
    "\n",
    "    # Prior:\n",
    "    prior = stats.norm(mu0, w0)\n",
    "    # Likelihood:\n",
    "    like = stats.norm(dbar, w)\n",
    "\n",
    "    #computer posterior mean, std, distribution\n",
    "    B = w**2/(w**2+w0**2)\n",
    "    mu_s =dbar+B*(mu0-dbar)\n",
    "    w_s = w*sqrt(1-B)\n",
    "    posterior = stats.norm(mu_s, w_s)\n",
    "    return mu_s\n",
    "\n",
    "\n",
    "\n",
    "def mean_var_opt(posLB, posUB, t, tickers, increments_for_graph, Cov, muf, mean_vect):\n",
    "    \"\"\"\n",
    "    posLB,posUB: upper and lower bounds for individual positions\n",
    "    t: number to multiply expected returns by to make them yearly\n",
    "    tickers: list of column names\n",
    "    increments_for_graph: decreasing this number increases the number of portfolios calculated\n",
    "    Cov: covariance of returns\n",
    "    muf: should be a single value\n",
    "    mean_vect: should be mean of dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    Cov = 2 * np.array(Cov)\n",
    "    mean_vect = mean_vect * t\n",
    "    muf  = muf * t\n",
    "    m = len(tickers)\n",
    "\n",
    "    from scipy.optimize import linprog\n",
    "    #set equality constraints. I want my positions to sum to 1\n",
    "    A_eq = np.array((1,)*m).reshape(1,-1)\n",
    "    b_eq = [1]\n",
    "\n",
    "    # set bounds on leverage. We can short but we can not go long\n",
    "    bounds = np.vstack([(posLB,)*m, (posUB,)*m]).T\n",
    "\n",
    "    #find min and max return\n",
    "    min_rtn = mean_vect @ linprog(c=mean_vect, A_eq = A_eq, b_eq = b_eq, bounds=bounds).x\n",
    "    max_rtn = mean_vect @ linprog(c=-mean_vect, A_eq = A_eq, b_eq = b_eq, bounds=bounds).x\n",
    "\n",
    "    from qpsolvers import solve_qp\n",
    "    muP = np.arange(min_rtn * .995,max_rtn * .995, increments_for_graph)\n",
    "    sdP = np.zeros(len(muP))\n",
    "    weights = np.zeros([len(muP),m])\n",
    "\n",
    "    q_vec = np.zeros(m).reshape(-1,)\n",
    "    G = np.zeros([m,m])\n",
    "    h = np.zeros(m)\n",
    "    A = np.vstack([np.array((1,)*m).reshape(1,-1),mean_vect])\n",
    "\n",
    "    #calculate each optimized portfolio for each mean\n",
    "    for i in range(len(muP)):\n",
    "        b = np.array([1,muP[i]])\n",
    "        weights[i] = solve_qp(P=Cov, q = q_vec, G=G, h=h, A=A, b=b, lb = bounds[:,0], ub = bounds[:,1])\n",
    "        sdP[i] = np.sqrt(weights[i] @ (Cov/2) @ weights[i]) * np.sqrt(t)\n",
    "    \n",
    "    portfolios = pd.DataFrame({'Returns': muP, 'Volatility': sdP,})\n",
    "    for counter, symbol in enumerate(tickers):\n",
    "        portfolios[symbol+' weight'] = [w[counter] for w in weights]\n",
    "    \n",
    "    portfolios['Sharpe'] = (portfolios['Returns']-muf) / portfolios['Volatility'] #note using monthly returns and vol\n",
    "\n",
    "    tangent = portfolios.iloc[[portfolios.Sharpe.argmax()]]\n",
    "    min_var = portfolios.iloc[[portfolios.Volatility.argmin()]]\n",
    "    efficient_portfolios = portfolios[portfolios['Returns'] >= min_var.Returns.values[0]-.02] #the .02 is arbitrary to see a bit below the min var port too\n",
    "\n",
    "    return tangent, min_var, efficient_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f198ab-8e0b-4a72-b0c7-cbcd7904ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix asssumption of means being normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd97dd8b-f5c9-4459-8c8c-e90df07093dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data, wb\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from norm_norm import *\n",
    "from scipy import stats, integrate\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba4f16c-d2d1-4226-beaf-f67aa5a6007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2010,1,1)\n",
    "end = datetime(2015,6,19)#when XLRE,XLC was introduced\n",
    "tickers = ['XLV','XLI','XLB','XLK','XLU','XLY','XLP','XLF','XLE'] #XLRE, XLC\n",
    "sectordata = import_data(tickers, start, end).resample(\"W\").apply(lambda x: ((x + 1).cumprod()-1).last(\"D\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7858d845-6094-45c3-930f-84a1e7b3f9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XLV</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLB</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLU</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLF</th>\n",
       "      <th>XLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-10</th>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>-0.009884</td>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.025335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-17</th>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>-0.032073</td>\n",
       "      <td>-0.016493</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>-0.013491</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>-0.018397</td>\n",
       "      <td>-0.017247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-24</th>\n",
       "      <td>-0.017381</td>\n",
       "      <td>-0.042312</td>\n",
       "      <td>-0.064201</td>\n",
       "      <td>-0.044131</td>\n",
       "      <td>-0.035263</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>-0.017930</td>\n",
       "      <td>-0.050870</td>\n",
       "      <td>-0.049949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>-0.012002</td>\n",
       "      <td>-0.016523</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>-0.032317</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>-0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-07</th>\n",
       "      <td>-0.014386</td>\n",
       "      <td>-0.006574</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>-0.020657</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>-0.008397</td>\n",
       "      <td>-0.016925</td>\n",
       "      <td>-0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-24</th>\n",
       "      <td>0.009696</td>\n",
       "      <td>-0.003677</td>\n",
       "      <td>-0.007571</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>-0.005826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>-0.000533</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.009976</td>\n",
       "      <td>-0.005275</td>\n",
       "      <td>-0.001570</td>\n",
       "      <td>-0.008318</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>-0.010459</td>\n",
       "      <td>-0.022568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-07</th>\n",
       "      <td>-0.008007</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>-0.024595</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>-0.009185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-14</th>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>-0.009270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-21</th>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>-0.007661</td>\n",
       "      <td>-0.006962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 XLV       XLI       XLB       XLK       XLU       XLY  \\\n",
       "Date                                                                     \n",
       "2010-01-10  0.005378  0.032839  0.026455 -0.009884 -0.011583  0.013000   \n",
       "2010-01-17  0.013845 -0.006154 -0.032073 -0.016493  0.006185 -0.013491   \n",
       "2010-01-24 -0.017381 -0.042312 -0.064201 -0.044131 -0.035263 -0.032022   \n",
       "2010-01-31 -0.012002 -0.016523 -0.047107 -0.032317 -0.009725 -0.003790   \n",
       "2010-02-07 -0.014386 -0.006574  0.011281  0.005248 -0.020657 -0.004842   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2015-05-24  0.009696 -0.003677 -0.007571  0.006696  0.005641  0.004570   \n",
       "2015-05-31 -0.000533 -0.019156 -0.009976 -0.005275 -0.001570 -0.008318   \n",
       "2015-06-07 -0.008007  0.000896 -0.011855 -0.009684 -0.040000  0.002883   \n",
       "2015-06-14  0.001345  0.002148  0.003799 -0.006519 -0.004214  0.000915   \n",
       "2015-06-21  0.020564  0.000297  0.004770  0.001439  0.015026  0.014442   \n",
       "\n",
       "                 XLP       XLF       XLE  \n",
       "Date                                      \n",
       "2010-01-10 -0.003750  0.036079  0.025335  \n",
       "2010-01-17  0.007527 -0.018397 -0.017247  \n",
       "2010-01-24 -0.017930 -0.050870 -0.049949  \n",
       "2010-01-31 -0.003423  0.000000 -0.031972  \n",
       "2010-02-07 -0.008397 -0.016925 -0.004770  \n",
       "...              ...       ...       ...  \n",
       "2015-05-24 -0.010050  0.006478 -0.005826  \n",
       "2015-05-31 -0.009340 -0.010459 -0.022568  \n",
       "2015-06-07 -0.024595  0.007724 -0.009185  \n",
       "2015-06-14  0.009876  0.010084 -0.009270  \n",
       "2015-06-21  0.018760 -0.007661 -0.006962  \n",
       "\n",
       "[285 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectordata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aae87557-edc5-4e86-82d0-26969894c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated expected return array\n",
    "def likelihood_n_posterior_mus(n, data, period=16): #period of 16 is 3 months with weekly data\n",
    "    like_mus = np.zeros(len(data.columns))\n",
    "    post_mus = np.zeros(len(data.columns))\n",
    "\n",
    "    for ints,sector in enumerate(data.columns):\n",
    "        likelihood_pop = np.array(data.iloc[n:n+period][sector])\n",
    "        prior_pop = np.array(data.iloc[n:n+period])\n",
    "        like_mus[ints] = likelihood_pop.mean() #normal mean opt \n",
    "        post_mus[ints] = calculate_posterior_mean(likelihood_pop,prior_pop) #bayesian means \n",
    "    return like_mus, post_mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440787ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate weighted means vector and cov matrix\n",
    "def weighted_stuff(n, data, period=16):\n",
    "    dat = np.array(data.iloc[n:n+period])\n",
    "    alpha = 0.5\n",
    "    weights = np.flip((1-alpha)**np.arange(0,period,1))\n",
    "    weights = weights/np.sum(weights) # normalize\n",
    "    weighted = dat.T*weights\n",
    "    w_means = np.sum(weighted,axis=1)                             # weighted means\n",
    "    w_covs = dat.T@np.diag(weights)@dat-np.outer(w_means,w_means) # weighted covs\n",
    "    return w_means, w_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a97aafd-accf-4d0f-a56a-de6afe0e8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tangent_rebalance(stocks, n, formation_period, port, weights, total,expt_rtn = 'like', Lower_bound=0, Upper_bound=1,annualizer = 52, muf = 0):\n",
    "    likeMu, postMu = likelihood_n_posterior_mus(n, period=formation_period, data = stocks)\n",
    "    cov = stocks[n-formation_period : n - 1].cov()\n",
    "    if expt_rtn == 'like':\n",
    "        tangent, min_var,eff_front = mean_var_opt(Lower_bound, Upper_bound, annualizer, stocks.columns, .01, cov, muf, likeMu)\n",
    "    elif expt_rtn == 'not like':\n",
    "        tangent, min_var,eff_front = mean_var_opt(Lower_bound, Upper_bound, annualizer, stocks.columns, .01, cov, muf, postMu)\n",
    "    return np.array(tangent.iloc[:,2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8ef44c4-cb74-4723-9328-685712d8e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(weights, col, dataf, expt_rtns = 'like', days_between_rebalance=1, show_weights=False, wealth = 1, RebalanceOffset=0, give='R',formation = 0): #cols allows users to backtest subsets of dataframe\n",
    "    \"\"\"\n",
    "    weights: tells the function the number of assets. sets the starting weights and is the weights for constant rebalancing\n",
    "    wealth: sets starting value\n",
    "    RebalanceOffset: to offset day of rebalances by these values to provide information about rebalance timing luck\n",
    "    give: return returns or prices\n",
    "    formation: number of days covariance matrix is formed over\n",
    "    \n",
    "    \"\"\"\n",
    "    colin=[0]*len(weights)\n",
    "    port=[0]*len(weights)\n",
    "    worth=[wealth]\n",
    "\n",
    "    for n in range(len(weights)):\n",
    "        colin[n] = dataf.columns.get_loc(col[n])\n",
    "        port[n]=wealth*weights[n]\n",
    "\n",
    "    for n in range (formation,len(dataf)):\n",
    "        port = np.multiply(port, np.array((1+dataf.iloc[n,colin])))\n",
    "        end_of_day = sum(port)\n",
    "        worth.append(end_of_day)\n",
    "        \n",
    "        if ((n + RebalanceOffset)% days_between_rebalance==0):        #rebalance\n",
    "            #port=rebalance_func(dataf, n, formation, port, weights, sum(port))\n",
    "#             port=tangent_rebalance(dataf, n, formation, port, weights, expt_rtns)\n",
    "            port=tangent_rebalance(dataf, n, formation, port, weights, None, expt_rtns)\n",
    "            if show_weights == True:\n",
    "                print(np.round(np.array(port/sum(port)),2))\n",
    "                \n",
    "    if (give=='R'):            \n",
    "        p_rtn = pd.DataFrame(worth).pct_change()[1:].set_index(dataf.index[formation:])\n",
    "        return(p_rtn)\n",
    "    if (give=='P'):\n",
    "        return(pd.DataFrame(worth[1:]).set_index(dataf.index[formation:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7614ea38-f1df-4219-9561-07c48a902aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.ones(len(sectordata.columns))/len(sectordata.columns)\n",
    "\n",
    "#standard covariance 3month lookback for expted returns and covariance\n",
    "likelihood = backtest(initial_weights, sectordata.columns, sectordata, formation = 16, expt_rtns = 'like')\n",
    "posterior = backtest(initial_weights, sectordata.columns, sectordata, formation = 16, expt_rtns = 'not like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ab597f4-8dd6-4c99-a4e8-278fa9ec1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = pd.concat([likelihood.rename({0:'like'},axis=1),posterior.rename({0:'post'},axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeb3df34-b9ee-4631-b15e-75608a4ad9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3724/3776587851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomparisons\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "((comparisons+1).cumprod()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07d9e0c2-ad48-4cab-a5a8-ad651f84bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fa35076-6b2f-45ad-b5a0-726e0b798254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taino\\AppData\\Local\\Temp/ipykernel_3724/1145077452.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  comparisons.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d8bdc-0ec0-48b9-acb9-cc1a07c77363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is fixed -> something wrong in my code? results are the same\n",
    "#But I'm now getting \"TypeError: no numeric data to plot\" when plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022556cb-3a30-4d7e-86d1-90394955ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next do exponentially weighted covariance matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
